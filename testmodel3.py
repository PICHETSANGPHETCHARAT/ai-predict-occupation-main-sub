import pandas as pd
import numpy as np
import asyncio
import json
import joblib
import mysql.connector
from openai import OpenAI
from pythainlp.tokenize import word_tokenize
from gensim.models import Word2Vec
from sklearn.metrics.pairwise import cosine_similarity

# üîπ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö...")
try:
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• RandomForest
    rf_model = joblib.load('models/occupation_rf_model.joblib')
    # ‡πÇ‡∏´‡∏•‡∏î TF-IDF Vectorizer
    vectorizer = joblib.load('models/tfidf_vectorizer.joblib')
    # ‡πÇ‡∏´‡∏•‡∏î LabelEncoder
    le_occupation = joblib.load('models/label_encoder.joblib')
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Word2Vec
    w2v_model = Word2Vec.load('models/word2vec_model.bin')
    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
    occupation_mapping = pd.read_csv('models/occupation_mapping.csv')
    
    print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
except Exception as e:
    print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {str(e)}")
    exit(1)

# üîπ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Cosine Similarity (‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
try:
    df = pd.read_csv("Updated_Occupation_Titles.csv", encoding="utf-8")
    df = df.dropna()
    df["‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô"] = df["‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô"].str.replace(r"[^\w\s]", "", regex=True)
    X = vectorizer.transform(df["‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô"])
    print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Cosine Similarity ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
except Exception as e:
    print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Cosine Similarity: {str(e)}")
    df = None
    X = None

# üîπ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå
def get_document_vector(tokens, model, vector_size=100):
    vec = np.zeros(vector_size)
    count = 0
    for word in tokens:
        try:
            vec += model.wv[word]
            count += 1
        except KeyError:
            continue
    if count != 0:
        vec /= count
    return vec

# üîπ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
def get_db_connection_120other():
    return mysql.connector.connect(
        host="192.168.100.120",
        user="jobbkk_other",
        password="orerthjobk2022$",
        database="jobbkk_other",
    )

# üîπ ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≠‡∏ö‡πÄ‡∏à‡∏Å‡∏ï‡πå
class OccupationSub:
    def __init__(self, occupation_sub_id, name):
        self.occupation_sub_id = occupation_sub_id
        self.name = name

    @classmethod
    def from_db(cls, db_record):
        return cls(
            occupation_sub_id=db_record["occupation_sub_id"], name=db_record["name"]
        )

# üîπ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏£‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
async def get_occupation_subs(occupation_id: int):
    try:
        conn = get_db_connection_120other()
        if not conn:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
            return []

        cursor = conn.cursor(dictionary=True)
        cursor.execute(
            """
           SELECT 
               os.id AS occupation_sub_id,
               od.name 
           FROM 
               occupation_sub os
               INNER JOIN occupation_sub_description od ON os.id = od.occupation_sub_id 
           WHERE 
               os.occupation_id = %s 
               AND os.is_status = '1'
               AND os.is_flags = '0'
               AND os.is_online = '1'
               AND od.language_id = '1'
               ORDER BY CONVERT(od.name USING tis620) ASC;
        """,
            (occupation_id,),
        )

        occupation_subs = cursor.fetchall()
        cursor.close()
        conn.close()

        return [
            OccupationSub.from_db(sub) for sub in occupation_subs
        ]

    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}")
        return []

# üîπ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ ChatGPT API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏£‡∏≠‡∏á
async def predict_sub_occupation_with_gpt(job_title, main_occupation, sub_occupations):
    try:
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏£‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        sub_options = [
            {"id": sub.occupation_sub_id, "name": sub.name} for sub in sub_occupations
        ]

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á ChatGPT API
        prompt = f"""
        ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô: "{job_title}"
        ‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏´‡∏•‡∏±‡∏Å: "{main_occupation}"
        
        ‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏£‡∏≠‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ô‡∏µ‡πâ:
        {json.dumps(sub_options, ensure_ascii=False)}
        
        ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢ ID ‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏£‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON: {{"occupation_sub_id": ID}}
        """

        import os
        open_api_key = os.getenv("OPENAI_API_KEY")
        client = openai.OpenAI(api_key=open_api_key)

        # ‡πÉ‡∏ä‡πâ OpenAI ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô"},
                {"role": "user", "content": prompt},
            ],
        )

        # ‡∏î‡∏∂‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö
        content = completion.choices[0].message.content

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON
        try:
            response_data = json.loads(content)
            sub_id = response_data.get("occupation_sub_id")

            # ‡∏´‡∏≤ sub_occupation ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö ID
            for sub in sub_occupations:
                if sub.occupation_sub_id == sub_id:
                    return sub.occupation_sub_id, sub.name

            return None, "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏£‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö ID"
        except json.JSONDecodeError:
            return None, "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å API ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"

    except Exception as e:
        return None, f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"

# üîπ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏£‡∏≠‡∏á
async def predict_job_category(job_title):
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ TF-IDF
    job_vector = vectorizer.transform([job_title])
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö Word2Vec
    tokens = word_tokenize(job_title, engine='newmm')
    
    # üî• ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏î‡πâ‡∏ß‡∏¢ RandomForest
    main_category_encoded = rf_model.predict(job_vector)[0]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
    probabilities = rf_model.predict_proba(job_vector)[0]
    top_3_indices = np.argsort(probabilities)[::-1][:3]
    top_3_categories_encoded = top_3_indices
    top_3_categories = le_occupation.inverse_transform(top_3_indices)
    top_3_probs = probabilities[top_3_indices]
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å
    print("\n‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏´‡∏•‡∏±‡∏Å (3 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å):")
    for cat_encoded, cat, prob in zip(top_3_categories_encoded, top_3_categories, top_3_probs):
        cat_name = occupation_mapping[occupation_mapping["occupation_id"] == cat]["‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏´‡∏•‡∏±‡∏Å"].values
        cat_name = cat_name[0] if len(cat_name) > 0 else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        print(f"‡∏£‡∏´‡∏±‡∏™: {cat} ({cat_encoded}), ‡∏ä‡∏∑‡πà‡∏≠: {cat_name}, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô: {prob:.4f}")

    # ‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô int
    main_category = le_occupation.inverse_transform([main_category_encoded])[0]
    main_category = int(main_category)

    # üîπ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏´‡∏•‡∏±‡∏Å
    main_category_name = occupation_mapping[occupation_mapping["occupation_id"] == main_category]["‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏´‡∏•‡∏±‡∏Å"].values
    main_category_name = main_category_name[0] if len(main_category_name) > 0 else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

    # üî• ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏£‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    sub_occupations = await get_occupation_subs(main_category)

    if sub_occupations:
        # üî• ‡πÉ‡∏ä‡πâ ChatGPT API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏£‡∏≠‡∏á
        sub_id, sub_name = await predict_sub_occupation_with_gpt(
            job_title, main_category_name, sub_occupations
        )
        return main_category, main_category_name, sub_id, sub_name
    else:
        return main_category, main_category_name, None, "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏£‡∏≠‡∏á"

# üî• ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
async def main():
    print("\nüîé ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
    print("============================")
    
    # üî• ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Terminal ‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ
    while True:
        job_example = input(
            "\nüîé ‡∏õ‡πâ‡∏≠‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (‡∏û‡∏¥‡∏°‡∏û‡πå 'q' ‡∏´‡∏£‡∏∑‡∏≠ 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å): "
        )

        if job_example.lower() in ["q", "exit"]:
            print("üëã ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
            break

        try:
            predicted_main, predicted_main_name, predicted_sub, predicted_sub_name = (
                await predict_job_category(job_example)
            )

            print("\nüìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:")
            print(f"‚úÖ ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á '{job_example}' ‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏•‡∏±‡∏Å: {predicted_main} ({predicted_main_name})")
            print(f"‚úÖ ‡∏´‡∏°‡∏ß‡∏î‡∏£‡∏≠‡∏á: {predicted_sub} ({predicted_sub_name})")
                
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {str(e)}")

# ‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏î‡πâ‡∏ß‡∏¢ asyncio
if __name__ == "__main__":
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå models ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    import os
    if not os.path.exists('models'):
        os.makedirs('models')
        
    asyncio.run(main())